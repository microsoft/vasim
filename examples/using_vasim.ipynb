{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VASIM Autoscaling Simulator Toolkit Example\n",
    "\n",
    "### Goals\n",
    "\n",
    "1. **Applicability:** Integration with various algorithms and parameter customization.\n",
    "\n",
    "2. **Simulation:** Realistic workload modeling, achieved within minutes.\n",
    "\n",
    "3. **Parameter Tuning:** Fine-tuning for optimal performance and cost savings.\n",
    "\n",
    "4. **Cost Analysis:** Demonstrating potential cost savings.\n",
    "\n",
    "\n",
    "### Overview: Autoscaling Components\n",
    "\n",
    "\n",
    "<img src=\"../docs/demo_pics/Autoscaling_infra.png\" alt=\"Autoscaling Components\" title=\"Autoscaling Components\" width=\"300\" >\n",
    "\n",
    "- Application: The running software, such as Postgres and SQL Server.\n",
    "- Controller: Manages tasks and publishes metrics.\n",
    "- Metrics Server: Stores and provides metrics.\n",
    "- Recommender Algorithm: Makes resource allocation decisions.\n",
    "- Scaler Entity: Enacts decisions, adjusting resource allocation.\n",
    "\n",
    "These components work together for effective autoscaling.\n",
    "\n",
    "\n",
    "### Components\n",
    "\n",
    "VASIM is a standalone Python package that internally replicates these components, maintaining and processing scaling states. It also includes a cluster state simulator for current utilization and limits, along with a post-processing analyzer for performance assessment. Input is in the same format as timestamp and utilization datasets. Output is a set of metrics and scaling decision trace.\n",
    "\n",
    "VASIM allows you to try different recommender algorithms to adapt to different workloads. Workloads can be bursty, monotononic, cyclical, and business needs may vary based on complexity, cost, and performance.\n",
    "\n",
    "<img src=\"../docs/demo_pics/VASim_infra.png\" alt=\"VASIM Overview\" title=\"VASIM Overview\" width=\"300\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "First, clone the code. You'll be modifying some of the python files, so make sure to add the `-e` to make it editable.  If you have not done this yet, uncomment the block below and run it.  (We leave it as commented out for now to avoid accidentally rerunning it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# git clone https://github.com/microsoft/vasim.git .\n",
    "# cd vasim\n",
    "# python -m pip install -e .[dev]\n",
    "# cd examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Prepare data:\n",
    "Get your test data. For this experiment we'll be working with the [Alibaba dataset](https://github.com/alibaba/clusterdata), trace c_12104.\n",
    "\n",
    "There are some important things to note about the data for Vasim.\n",
    "\n",
    "1. You currently must name your csv's ending with `perf_event_log.csv`. (Ex: `c_12104.csv_perf_event_log.csv`.)  This is so the ingester does not accidentally read in other files in the directory such as output files.\n",
    "2. You must format your data in two columns (`TIMESTAMP`,`CPU_USAGE_ACTUAL`) as follows:  (TODO: We [plan](https://github.com/microsoft/vasim/issues/34) to use Open Telemetry format in the future.) \n",
    "3. You may have multiple CSVs, just put everything in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP,CPU_USAGE_ACTUAL\n",
      "2023.04.02-00:09:00:000,7.2\n",
      "2023.04.02-00:10:00:000,7.04\n",
      "2023.04.02-00:11:00:000,6.88\n",
      "2023.04.02-00:12:00:000,6.72\n",
      "2023.04.02-00:13:00:000,6.48\n",
      "2023.04.02-00:14:00:000,6.501818181818182\n",
      "2023.04.02-00:15:00:000,6.523636363636364\n",
      "2023.04.02-00:16:00:000,6.545454545454546\n",
      "2023.04.02-00:17:00:000,6.567272727272727\n"
     ]
    }
   ],
   "source": [
    "! head data/c_12104.csv_perf_event_log.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare algorithm\n",
    "\n",
    "You also need to implement your Recommender algorithm. There are examples in the [recommender](../recommender) folder.\n",
    "\n",
    "To implement a recommender you will need to create a file for your algorithm, add any paramters you need to the `__init__` function and then implement the core logic of your recommender in the `run()` function.\n",
    "\n",
    "```python\n",
    "class SimpleAdditiveRecommender(Recommender):\n",
    "    def __init__(self, cluster_state_provider, save_metadata=True):\n",
    "        # Copy the code at the top of this function as-is.\n",
    "\n",
    "        # Put your parameters here hard-coded, or pass them in to your\n",
    "        # `metadata.json` file in the `algo_specific_config` section.\n",
    "        self.my_param = self.algo_params.get(\"myparam\", 2)\n",
    "\n",
    "    def run(self, recorded_data):\n",
    "        \"\"\"\n",
    "        This method runs the recommender algorithm and returns the new number of\n",
    "              cores to scale to (new limit).\n",
    "\n",
    "        Inputs:\n",
    "            recorded_data (pd.DataFrame): The recorded metrics data for the current time window to simulate\n",
    "        Returns:\n",
    "            latest_time (datetime): The latest time of the performance data.\n",
    "            new_limit (float): The new number of cores to scale to.\n",
    "        \"\"\"\n",
    "\n",
    "        # Your logic goes here! Look at the data in the `recorded_data` dataframe,\n",
    "        #   do a calculation, and return the number of cores to scale to.\n",
    "\n",
    "        return new_limit\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we'll be working with the [DummyAdditiveRecommender](../recommender/DummyAdditiveRecommender.py), which takes a moving average of the CPU values and adds a fixed buffer amount to the top.\n",
    "\n",
    "We'll define a parameter: `\"addend\": 2`, and this will add `2` CPU cores to the limit, providing a healthy buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metadata.json\n",
    "We also need to prepare a file that provides the default set of configuration parameters. You can see some examples of this file in [the test folder](../tests/test_data/alibaba_control_c_29247_denom_1_mini). The default name of this file is `metadata.json`, but you can give it any name and pass it in as a parameter.\n",
    "\n",
    "There are three sets of parameters:\n",
    "* **`algo_specific_config`** : this is where you put the parameters you will use in your algorithm's `run` function\n",
    "  * An example: `addend: 2` for the `DummyAdditiveRecommender` we'll be using for this example.\n",
    "* **`general_config`** : These are the parameters related to how the csv trace data is passed in, and the simulation safe-guards.\n",
    "  * `window` (int): the amount of data that is passed to the algorithm in the `recorded_data` paramaeter in the `run` function. _See \"original window\" below_\n",
    "  * `lag` (float): Number of minutes to wait after making a decision\n",
    "  * `min_cpu_limit` (int): The minimum number of cores to recommend. This is used as a [safety guard](https://github.com/microsoft/vasim/blob/198a06062a91f6455b87710b0e59834530b6ea29/simulator/SimulatedInfraScaler.py#L56) in the simulated infra.\n",
    "  * `max_cpu_limit` (int): The maximum number of cores to recommend. (same as min)\n",
    "  * `recovery_time` (int of minutes, optional, default is 15): The **minimum** amount of time in minutes to wait before making another scaling decision.\n",
    "  * `granularity` (int, unused): This needs to be removed [#35](https://github.com/microsoft/vasim/issues/35), but for now it must be an integer.\n",
    "* **`prediction_config`** : this relates to the window of [predicted](https://github.com/microsoft/vasim/blob/198a06062a91f6455b87710b0e59834530b6ea29/recommender/cluster_state_provider/PredictiveFileClusterStateProvider.py#L29) data that is fed into the algorithm. It uses a time series to forecast what the data might be in the future to help the algorithm proactively scale\n",
    "  * `waiting_before_predict` (int of minutes) : This is the amount of data to consume before making prediction. It is usually set to `1440`, for 60 min * 24 hours = 1 day. In general, it is waiting for one full cycle of data (`period` in the graph below) to pass. Sometimes this is daily, sometimes weekly, etc.  TODO: autodetermine this.\n",
    "  * `frequency_minutes` (int) : This is how frequent your timestamps are in the csvs you provide. This *MUST* match your csvs.  (Ex: 1 in the above case.) TODO: automate.\n",
    "  * `forecasting_models` (string, unused): For now we only support \"naive\".  This parameter is not currently used because it's the only thing supported. However, you still must provide a string for now as a placeholder\n",
    "  * `minutes_to_predict` (int): This is the “forecasting horizon” below/how much to look forward.  Increasing this means you’ll be MORE proactive in adjusting based on history. This is a good one to tune depending on how consisten your data is.\n",
    "  * `total_predictive_window` (int): _This is the \"new window\" in the diagram below_, essentially the total amount of minutes you want in the window. A common setting for this parameter is `minutes_to_predict`/`frequency_minutes` + `window`.  If you would like to change this, you can do it here. \n",
    "   \n",
    "\n",
    "Some important things to note:\n",
    "* `recovery_time` means that the simulator will NOT scale up/down even if the decision indicates to scale, until that minimum number of minutes has passed. This simulates a live system recovering.\n",
    "* `lag` is the number of minutes to wait between making a decision/running your `run()` function. For example, for very heavy-weight algorithms, you may only want to run every 10 minutes. This also is used to prevent thrashing.\n",
    "\n",
    "Here is a picture that explains the `window` and `prediction_config`:\n",
    "\n",
    "<img src=\"../docs/demo_pics/predictive_window.png\" alt=\"Data Windows\" title=\"Data Windows\" >\n",
    "\n",
    "Here is an example of the `metadata.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"algo_specific_config\": {\n",
      "        \"addend\": 2\n",
      "    },\n",
      "    \"general_config\": {\n",
      "        \"window\": 20,\n",
      "        \"lag\": 10,\n",
      "        \"max_cpu_limit\": 25,\n",
      "        \"min_cpu_limit\": 2.0,\n",
      "        \"granularity\": 1\n",
      "    },\n",
      "    \"prediction_config\": {\n",
      "        \"waiting_before_predict\": 1440,\n",
      "        \"frequency_minutes\": 1,\n",
      "        \"minutes_to_predict\": 10,\n",
      "        \"forecasting_models\": \"naive\",\n",
      "        \"total_predictive_window\": 30\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat data/metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "Once you have all three (CSV, algo, metadata), for now, there is one last step. (TODO: [Issue #19](https://github.com/microsoft/vasim/issues/19))  You must currently [add the name of your algorithm to the simulator](https://github.com/microsoft/vasim/blob/9b50d9080d4a26fbad014159484fd110af95fa75/simulator/InMemorySimulator.py#L87) for it to be called, and import it at the top of the [InMemorySimulator.py file](../simulator/InMemorySimulator.py).\n",
    "\n",
    "```python\n",
    " def _create_recommender_algorithm(self, algorithm):\n",
    "        if algorithm == 'multiplicative':\n",
    "            return SimpleMultiplierRecommender(self.cluster_state_provider)\n",
    "        elif algorithm == 'additive':\n",
    "            return SimpleAdditiveRecommender(self.cluster_state_provider)\n",
    "        # Add your own algorithm here!!!\n",
    "        # TODO: Make this more dynamic\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown algorithm: {algorithm}\")\n",
    "```\n",
    "\n",
    "**REMEMEBER: You must reload this notebook/restart the kernel for Python to see your new algorithm**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with a single simulation\n",
    "\n",
    "Now that we have the csv, algorithm, and parameter config, we can run a single simulation for a fixed set of parameters.\n",
    "\n",
    "`initial_cpu_limit` is the current limit that your system is set to. (TODO: we could move this to `metadata.json` but we found that value changed more than the other variables in the file, so for now it is a parameter.)\n",
    "\n",
    "\n",
    "##### Important\n",
    "If you get an error below that is something like `KeyError: \"Cannot get left slice bound for non-unique label: Timestamp...` this is because you have some non perf_event_log.csvs in your \"data\" folder, most likely output in the `_siulations` output folder. This is a [bug](https://github.com/microsoft/vasim/issues/18).\n",
    "\n",
    "To prevent this, let's clear out old output files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# clear out CSV results from prior runs\n",
    "! rm -rf data/_simulations\n",
    "! rm -rf data_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction config was detected:{'waiting_before_predict': 1440, 'frequency_minutes': 1, 'minutes_to_predict': 10, 'forecasting_models': 'naive', 'total_predictive_window': 30}\n",
      "config: {}\n",
      "logger: <RootLogger root (ERROR)>\n",
      "data_dir: /home/osdi-eval/vasim/examples/data\n",
      "features: ['cpu']\n",
      "decision_file_path: /home/osdi-eval/vasim/examples/data/_simulations/target_cfg-616e5eeb-ed74/decisions.txt\n",
      "save_metadata: True\n",
      "frequency_minutes: 1\n",
      "minutes_to_predict: 10\n",
      "freq: 1T\n",
      "waiting_time: 1440\n",
      "data_processor: <recommender.forecasting.utils.DataProcessor.DataProcessor object at 0x74c91b9a69e0>\n",
      "data_forecaster: <recommender.forecasting.TimeSeriesForecaster.TimeSeriesForecaster object at 0x74c91b9a5c60>\n",
      "cores: 0\n",
      "predicted_cores: 0\n",
      "_prediction_activated: False\n",
      "number_of_points_to_predict: 10\n",
      "predictive_window: 30\n",
      "curr_cpu_limit: None\n",
      "Starting simulation at 2023-04-02 00:09:00 and continuing till 2023-04-09 23:20:00\n",
      "Setting number of cores to 10\n"
     ]
    }
   ],
   "source": [
    "from simulator.InMemorySimulator import InMemoryRunnerSimulator\n",
    "\n",
    "# Specify your data directory, algorithm, initial cores count and config path if you did not name your metadata.json as metadata.json\n",
    "runner = InMemoryRunnerSimulator(data_dir=\"data/\",  algorithm=\"additive\", initial_cpu_limit=10, config_path=\"data/metadata.json\")\n",
    "\n",
    "results = runner.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "You can see in the output above that the metadata.json file is read and the simulation is run. The results are stored in the results variable. You can print the results to see the output.\n",
    "\n",
    "**NOTE** These results will also be saved in a folder started with `_simulations/target_*` with the `*` being a uniquely generated identifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pretty print the results\n",
    "import json\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### Understanding the output\n",
    "\n",
    "\n",
    "Of the json output above, the fields are as follows:\n",
    "* `average_slack` - The average slack in CPU cores across all the time intervals. (Ex: here it is 2.66 because the \"additive\" algorithm is adding 2 cores for a buffer)\n",
    "* `average_insufficient_cpu` - The average number of insufficient CPU cores across all the time intervals. (Ex: here it is nearly 0 because the \"additive\" algorithm is adding 2 cores for a buffer)\n",
    "* `sum_slack` - The sum of slack in CPU cores across all the time intervals.\n",
    "* `sum_insufficient_cpu` - The sum of CPU cores that were insufficient across all the time intervals.\n",
    "* `num_scalings` - The number of times the CPU was scaled by the simulated scaler.\n",
    "* `num_insufficient_cpu` - The number of times the CPU was insufficient across all the time intervals.\n",
    "* `insufficient_observations_percentage` - The percentage of times the CPU was insufficient across all the time intervals.\n",
    "* `slack_percentage` - The percentage of slack in CPU cores across all the time intervals.\n",
    "* `median_insufficient_cpu` - The median number of insufficient CPU cores across all the time intervals \n",
    "* `median_slack` - The median slack in CPU cores across all the time intervals.\n",
    "* `max_slack` - The maximum slack in CPU cores across all the time intervals.\n",
    "\n",
    "\n",
    "There is also a plot that will be generated in the `_simulations/target_*` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "You will also have a graph in your `_simulations/target*` folder that looks something like this, named `cpu_usage_and_new_limit.pdf`. The red line is the CPU limits your algorithm set, and the blue line is the real values provided in the csv.  You can see that the algorithm consistently set the limit about 2 CPUs above the running CPU total.\n",
    "\n",
    "<img src=\"../docs/demo_pics/cpu_usage_and_new_limit.png\" alt=\"Single Run Simulation\" title=\"Single Run Simulation\" width=\"450\" >\n",
    "\n",
    "This image is hard-coded here due to the random path and it being PDF rather than png."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to do some cleanup, we will delete this file to not conflict with others experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf data/_simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Getting started with multiple simulations and parameter tuning\n",
    "\n",
    "Now that you've run a single simulation for a single output, we'll move on to parameter tuning!  Looking at the parameter we have above, we have our \"addend\" buffer.  Another good one to due is the total window size to feed the algorithm. Since in our dummy example we smooth the entire window and add that as a buffer, we want to simulate the impact of changing that \n",
    "parameter.\n",
    "\n",
    "BTW: The `logger: <RootLogger root (ERROR)>` are expected for this setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from simulator.ParameterTuning import tune_with_strategy\n",
    "\n",
    "# First create some test data to tune\n",
    "config_path = \"data/metadata.json\"  # This will be the baseline\n",
    "algo_specific_params_to_tune = {\n",
    "    \"addend\": [1, 2, 3],  # the addend is the number of minutes to add to the prediction\n",
    "}\n",
    "params_to_tune = {\n",
    "    'window': [60, 120],  # the window size is the number of minutes to consider for the prediction\n",
    "}\n",
    "predictive_params_to_tune = None # For now, we will not tune the predictive model\n",
    "selected_algorithm = \"additive\"\n",
    "initial_cpu_limit = 10\n",
    "strategy = \"grid\"  # Options are \"grid\" and \"random\". Grid will try all combinations, random will try a random subset\n",
    "data_dir = \"data\"\n",
    "num_workers = 6  # how many threads to spin up. Here there are 6 (2*3) combinations possible, so we will use 6 threads\n",
    "num_combinations = 6\n",
    "\n",
    "# This will run all 6 combinations in parallel\n",
    "tune_with_strategy(config_path, strategy, num_combinations=num_combinations,\n",
    "                    num_workers=num_workers, data_dir=data_dir, lag=10,\n",
    "                    algorithm=selected_algorithm, initial_cpu_limit=initial_cpu_limit,\n",
    "                    algo_specific_params_to_tune=algo_specific_params_to_tune,\n",
    "                    general_params_to_tune=params_to_tune,\n",
    "                    predictive_params_to_tune=predictive_params_to_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above call `tune_with_strategy` will run all possible combinations for this `grid`. It will generate 6 folders, in a folder that ends in the token `_tuning`. For example, here it should be in the `data_tuning` folder, and inside that folder there should be 6 folders named as `target_uuid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# list the contents of the data_tuning directory\n",
    "! ls -l data_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these folders, you will see the saved output (`calc_metrics.json`) and also a graph like the one above named as `cpu_usage_and_new_limit.pdf`.\n",
    "\n",
    "### Plotting the Paretto curve\n",
    "\n",
    "But it is easier if we find the \"best\" combination, meaning lowest slack (excess CPU) and lowest throttling (insufficient CPU).  We can do that by plotting them on a Paretto curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from simulator.analysis.pareto_visualization import create_pareto_curve_from_folder\n",
    "\n",
    "# Now we'll plot them.  For parameters, put hte name of our folder, and the name of the output folder (Usually just the name of your folder with _tuning appended)\n",
    "pareto_2d = create_pareto_curve_from_folder(\"data\", \"data_tuning\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the plot\n",
    "from IPython.display import Image\n",
    "Image(filename='data_tuning/pareto_frontier.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see the pareto curve, saved to your tuning directory (ex: `data_tuning/pareto_frontier.png`).\n",
    "\n",
    "### More analysis\n",
    "\n",
    "The parameter combination that is the closest to (0,0) is marked with a green x and labeled with the last 4 digits of the uuid of the `target_cfg` folder.  You can read more details about this in the [paper](https://www.microsoft.com/en-us/research/publication/caasper-vertical-autoscaling/) in Figure 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns folder, config, dimension_1, and dimension_2 of the closest combination\n",
    "# We don't know what folder will be because it's random, but we can check the other values\n",
    "# We know that a config with the added value of 1 has the least slack and expect that to be the closest to zero\n",
    "folder, config, slack, insuff_cpu = pareto_2d.find_closest_to_zero()\n",
    "\n",
    "print(f\"Folder: {folder}\")\n",
    "# for config, we have a nested dictionary, so we need to print it out\n",
    "# now print all the configs\n",
    "print(\"All Configs:\")\n",
    "print(f\"algo_specific_config: {config.get('algo_specific_config')}\")\n",
    "print(f\"general_config: {config.get('general_config')}\")\n",
    "print(f\"predictive_config: {config.get('predictive_config')}\")\n",
    "\n",
    "print(f\"Slack: {slack}\")\n",
    "print(f\"Insufficient CPU: {insuff_cpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the original combinations:\n",
    "\n",
    "```python\n",
    "algo_specific_params_to_tune = {\n",
    "    \"addend\": [1, 2, 3],  # the addend is the number of minutes to add to the prediction\n",
    "}\n",
    "params_to_tune = {\n",
    "    'window': [60, 120],  # the window size is the number of minutes to consider for the prediction\n",
    "}\n",
    "```\n",
    "\n",
    "We see that the best parameter for `addend` is 1, which makes sense because it will have the lowest buffer and therefore the least slack. But you may take a different approach in your analsis depending on your goals. (Ex: some customers prefer larger buffer and would say that `3 producted better results.)\n",
    "\n",
    "We also see that the smaller window (`60` seconds) produced a better result. This is because for our smoothing algorithm, 120 minutes is too much data to do this effectively, a smaller amount is better.  \n",
    "\n",
    "Now you can play around with new parameters and see what results you get!  \n",
    "\n",
    "#### Important:\n",
    "\n",
    "Make sure you clean up your folder before rerunning the simulation, else you will get innacurate results or errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! rm -rf data/_simulations\n",
    "! rm -rf data_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
