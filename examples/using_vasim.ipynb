{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VASIM Autoscaling Simulator Toolkit Example\n",
    "\n",
    "### Goals\n",
    "\n",
    "1. **Applicability:** Integration with various algorithms and parameter customization.\n",
    "\n",
    "2. **Simulation:** Realistic workload modeling, achieved within minutes.\n",
    "\n",
    "3. **Parameter Tuning:** Fine-tuning for optimal performance and cost savings.\n",
    "\n",
    "4. **Cost Analysis:** Demonstrating potential cost savings.\n",
    "\n",
    "\n",
    "### Overview: Autoscaling Components\n",
    "\n",
    "\n",
    "<img src=\"../docs/demo_pics/Autoscaling_infra.png\" alt=\"Autoscaling Components\" title=\"Autoscaling Components\" width=\"300\" >\n",
    "\n",
    "- Application: The running software, such as Postgres and SQL Server.\n",
    "- Controller: Manages tasks and publishes metrics.\n",
    "- Metrics Server: Stores and provides metrics.\n",
    "- Recommender Algorithm: Makes resource allocation decisions.\n",
    "- Scaler Entity: Enacts decisions, adjusting resource allocation.\n",
    "\n",
    "These components work together for effective autoscaling.\n",
    "\n",
    "\n",
    "### Components\n",
    "\n",
    "VASIM is a standalone Python package that internally replicates these components, maintaining and processing scaling states. It also includes a cluster state simulator for current utilization and limits, along with a post-processing analyzer for performance assessment. Input is in the same format as timestamp and utilization datasets. Output is a set of metrics and scaling decision trace.\n",
    "\n",
    "VASIM allows you to try different recommender algorithms to adapt to different workloads. Workloads can be bursty, monotononic, cyclical, and business needs may vary based on complexity, cost, and performance.\n",
    "\n",
    "<img src=\"../docs/demo_pics/VASim_infra.png\" alt=\"VASIM Overview\" title=\"VASIM Overview\" width=\"300\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "\n",
    "### Prepare data:\n",
    "Get your test data. For this experiment we'll be working with the [Alibaba dataset](https://github.com/alibaba/clusterdata), trace c_12104.\n",
    "\n",
    "There are some important things to note about the data for Vasim.\n",
    "\n",
    "1. You currently must name your csv's ending with `perf_event_log.csv`. (Ex: `c_12104.csv_perf_event_log.csv`.)  This is so the ingester does not accidentally read in other files in the directory such as output files.\n",
    "2. You must format your data in two columns (`TIMESTAMP`,`CPU_USAGE_ACTUAL`) as follows:  (TODO: We [plan](https://github.com/microsoft/vasim/issues/34) to use Open Telemetry format in the future.) \n",
    "3. You may have multiple CSVs, just put everything in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP,CPU_USAGE_ACTUAL\n",
      "2023.04.02-00:09:00:000,7.2\n",
      "2023.04.02-00:10:00:000,7.04\n",
      "2023.04.02-00:11:00:000,6.88\n",
      "2023.04.02-00:12:00:000,6.72\n",
      "2023.04.02-00:13:00:000,6.48\n",
      "2023.04.02-00:14:00:000,6.501818181818182\n",
      "2023.04.02-00:15:00:000,6.523636363636364\n",
      "2023.04.02-00:16:00:000,6.545454545454546\n",
      "2023.04.02-00:17:00:000,6.567272727272727\n"
     ]
    }
   ],
   "source": [
    "! head data/c_12104.csv_perf_event_log.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare algorithm\n",
    "\n",
    "You also need to implement your Recommender algorithm. There are examples in the [recommender](../recommender) folder.\n",
    "\n",
    "To implement a recommender you will need to create a file for your algorithm, add any paramters you need to the `__init__` function and then implement the core logic of your recommender in the `run()` function.\n",
    "\n",
    "```python\n",
    "class SimpleAdditiveRecommender(Recommender):\n",
    "    def __init__(self, cluster_state_provider, save_metadata=True):\n",
    "        # Copy the code at the top of this function as-is.\n",
    "\n",
    "        # Put your parameters here hard-coded, or pass them in to your\n",
    "        # `metadata.json` file in the `algo_specific_config` section.\n",
    "        self.my_param = self.algo_params.get(\"myparam\", 2)\n",
    "\n",
    "    def run(self, recorded_data):\n",
    "        \"\"\"\n",
    "        This method runs the recommender algorithm and returns the new number of\n",
    "              cores to scale to (new limit).\n",
    "\n",
    "        Inputs:\n",
    "            recorded_data (pd.DataFrame): The recorded metrics data for the current time window to simulate\n",
    "        Returns:\n",
    "            latest_time (datetime): The latest time of the performance data.\n",
    "            new_limit (float): The new number of cores to scale to.\n",
    "        \"\"\"\n",
    "\n",
    "        # Your logic goes here! Look at the data in the `recorded_data` dataframe,\n",
    "        #   do a calculation, and return the number of cores to scale to.\n",
    "\n",
    "        return new_limit\n",
    "```\n",
    "\n",
    "For this example, we'll be working with the [DummyAdditiveRecommender](../recommender/DummyAdditiveRecommender.py), which takes a moving average of the CPU values and adds a fixed buffer amount to the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing metadata.json\n",
    "We also need to prepare a file that provides the default set of configuration parameters. You can see some examples of this file in [the test folder](../tests/test_data/alibaba_control_c_29247_denom_1_mini). The default name of this file is `metadata.json`, but you can give it any name and pass it in as a parameter.\n",
    "\n",
    "There are three sets of parameters:\n",
    "* **`algo_specific_config`** : this is where you put the parameters you will use in your algorithm's `run` function\n",
    "  * An example: `addend: 2` for the `DummyAdditiveRecommender` we'll be using for this example.\n",
    "* **`general_config`** : These are the parameters related to how the csv trace data is passed in, and the simulation safe-guards.\n",
    "  * `window` (int): the amount of data that is passed to the algorithm in the `recorded_data` paramaeter in the `run` function. _See \"original window\" below_\n",
    "  * `lag` (float): Number of minutes to wait after making a decision\n",
    "  * `min_cpu_limit` (int): The minimum number of cores to recommend. This is used as a [safety guard](https://github.com/microsoft/vasim/blob/198a06062a91f6455b87710b0e59834530b6ea29/simulator/SimulatedInfraScaler.py#L56) in the simulated infra.\n",
    "  * `max_cpu_limit` (int): The maximum number of cores to recommend. (same as min)\n",
    "  * `recovery_time` (int of minutes, optional, default is 15): The **minimum** amount of time in minutes to wait before making another scaling decision.\n",
    "  * `granularity` (int, unused): This needs to be removed [#35](https://github.com/microsoft/vasim/issues/35), but for now it must be an integer.\n",
    "* **`prediction_config`** : this relates to the window of [predicted](https://github.com/microsoft/vasim/blob/198a06062a91f6455b87710b0e59834530b6ea29/recommender/cluster_state_provider/PredictiveFileClusterStateProvider.py#L29) data that is fed into the algorithm. It uses a time series to forecast what the data might be in the future to help the algorithm proactively scale\n",
    "  * `waiting_before_predict` (int of minutes) : This is the amount of data to consume before making prediction. It is usually set to `1440`, for 60 min * 24 hours = 1 day. In general, it is waiting for one full cycle of data (`period` in the graph below) to pass. Sometimes this is daily, sometimes weekly, etc.  TODO: autodetermine this.\n",
    "  * `frequency_minutes` (int) : This is how frequent your timestamps are in the csvs you provide. This *MUST* match your csvs.  (Ex: 1 in the above case.) TODO: automate.\n",
    "  * `forecasting_models` (string, unused): For now we only support \"naive\".  This parameter is not currently used because it's the only thing supported. However, you still must provide a string for now as a placeholder\n",
    "  * `minutes_to_predict` (int): This is the “forecasting horizon” below/how much to look forward.  Increasing this means you’ll be MORE proactive in adjusting based on history. This is a good one to tune depending on how consisten your data is.\n",
    "  * `total_predictive_window` (int, optional): By [default](https://github.com/microsoft/vasim/blob/198a06062a91f6455b87710b0e59834530b6ea29/recommender/cluster_state_provider/PredictiveFileClusterStateProvider.py#L39), this parameter is `minutes_to_predict`/`frequency_minutes` + `window`.  If you would like to change this, you can do it here. \n",
    "   _This is the \"new window\" in the diagram below_, essentially the total amount of minutes you want \n",
    "\n",
    "Some important things to note:\n",
    "* `recovery_time` means that the simulator will NOT scale up/down even if the decision indicates to scale, until that minimum number of minutes has passed. This simulates a live system recovering.\n",
    "* `lag` is the number of minutes to wait between making a decision/running your `run()` function. For example, for very heavy-weight algorithms, you may only want to run every 10 minutes. This also is used to prevent thrashing.\n",
    "\n",
    "Here is a picture that explains the `window` and `prediction_config`:\n",
    "\n",
    "<img src=\"../docs/demo_pics/predictive_window.png\" alt=\"Data Windows\" title=\"Data Windows\" >\n",
    "\n",
    "Here is an example of the `metadata.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"algo_specific_config\": {\n",
      "        \"addend\": 2\n",
      "    },\n",
      "    \"general_config\": {\n",
      "        \"window\": 20,\n",
      "        \"lag\": 10,\n",
      "        \"max_cpu_limit\": 25,\n",
      "        \"min_cpu_limit\": 2.0,\n",
      "        \"granularity\": 1\n",
      "    },\n",
      "    \"prediction_config\": {\n",
      "        \"waiting_before_predict\": 1440,\n",
      "        \"frequency_minutes\": 1,\n",
      "        \"minutes_to_predict\": 10,\n",
      "        \"forecasting_models\": \"naive\"\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "! cat data/metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "Once you have all three (CSV, algo, metadata), for now, there is one last step. (TODO: [Issue #19](https://github.com/microsoft/vasim/issues/19))  You must currently [add the name of your algorithm to the simulator](https://github.com/microsoft/vasim/blob/9b50d9080d4a26fbad014159484fd110af95fa75/simulator/InMemorySimulator.py#L87) for it to be called, and import it at the top of the [InMemorySimulator.py file](../simulator/InMemorySimulator.py).\n",
    "\n",
    "```python\n",
    " def _create_recommender_algorithm(self, algorithm):\n",
    "        if algorithm == 'multiplicative':\n",
    "            return SimpleMultiplierRecommender(self.cluster_state_provider)\n",
    "        elif algorithm == 'additive':\n",
    "            return SimpleAdditiveRecommender(self.cluster_state_provider)\n",
    "        # Add your own algorithm here!!!\n",
    "        # TODO: Make this more dynamic\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown algorithm: {algorithm}\")\n",
    "```\n",
    "\n",
    "**REMEMEBER: You must reload this notebook/restart the kernel for Python to see your new algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with a single simulation\n",
    "\n",
    "Now that we have the csv, algorithm, and parameter config, we can run a single simulation for a fixed set of parameters.\n",
    "\n",
    "`initial_cpu_limit` is the current limit that your system is set to. (TODO: we could move this to `metadata.json` but we found that value changed more than the other variables in the file, so for now it is a parameter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'algorithm_config': {}, 'general_config': {'lag': 10, 'granularity': 1, 'min_cpu_limit': 2.0, 'max_cpu_limit': 25, 'window': 20}, 'prediction_config': {}}\n",
      "logger: <RootLogger root (ERROR)>\n",
      "data_dir: /home/osdi-eval/vasim/examples/data\n",
      "features: ['cpu']\n",
      "decision_file_path: /home/osdi-eval/vasim/examples/data/_simulations/target_79d24be0-7d45-4ae0-a53b-58fee0e01933/decisions.txt\n",
      "save_metadata: True\n",
      "frequency_minutes: 1\n",
      "minutes_to_predict: 10\n",
      "freq: 1T\n",
      "waiting_time: 1440\n",
      "data_processor: <recommender.forecasting.utils.DataProcessor.DataProcessor object at 0x71c52fd43ac0>\n",
      "data_forecaster: <recommender.forecasting.TimeSeriesForecaster.TimeSeriesForecaster object at 0x71c52fd43280>\n",
      "cores: 0\n",
      "predicted_cores: 0\n",
      "_prediction_activated: False\n",
      "number_of_points_to_predict: 10\n",
      "predictive_window: 30\n",
      "curr_cpu_limit: None\n",
      "JSON file successfully written.\n",
      "Starting simulation at 2023-04-02 00:09:00 and continuing till 2023-04-09 23:20:00\n",
      "Setting number of cores to 10\n",
      "Simulation finished at 2023-04-09 23:19:00\n",
      "JSON file successfully written.\n"
     ]
    }
   ],
   "source": [
    "from simulator.InMemorySimulator import InMemoryRunnerSimulator\n",
    "\n",
    "# Specify your data directory, algorithm, initial cores count and config path if you did not name your metadata.json as metadata.json\n",
    "runner = InMemoryRunnerSimulator(data_dir=\"data/\",  algorithm=\"additive\", initial_cpu_limit=10, config_path=\"data/metadata.json\")\n",
    "\n",
    "results = runner.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_slack': 2.6615605822802952, 'average_insufficient_cpu': 0.011724998250317914, 'sum_slack': 30477.530227691663, 'sum_insufficient_cpu': 134.26295496439045, 'num_scalings': 289, 'num_insufficient_cpu': 99, 'insufficient_observations_percentage': 0.8645533141210375, 'slack_percentage': 23.172159395780824, 'median_insufficient_cpu': 0.0, 'median_slack': 2.4399999999999995, 'max_slack': 8.236}\n"
     ]
    }
   ],
   "source": [
    "# print the\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
